INFO:root:Namespace(lm_model='roberta-base', N=50, max_len=128, z_dim=8, mha_dim=768, n_heads=8, gen_dims=[[128, 256, 768], [512, 512, 512]], disc_dims=[[128, 128], [512, 768], [512, 256, 128]], lambda_gp=5, lambda_rew=0, lambda_wgan=1, post_method='hard_gumbel', batch_size=128, num_epochs=100, g_lr=0.0002, d_lr=0.0002, b_lr=1e-05, r_lr=0.001, dropout=0.0, n_critic=4, test_epochs=100, num_workers=1, mode='train', bert_unfreeze=0, data_dir='data/graphgen', saving_dir='results/2023-04-22_12-50', model_save_step=20, lr_update_step=1000, restore_G=None, restore_D=None, restore_R=None, restore_B_D=None, restore_B_G=None, name='symm_fcn_final_ds_gumbel_roberta_adjonly', log_dir='results/2023-04-22_12-50/logs', model_dir='results/2023-04-22_12-50/models')
INFO:root:Generator(
  (activation_f): ReLU()
  (multi_dense_layer): MultiDenseLayer(
    (linear_layer): Sequential(
      (0): Linear(in_features=8, out_features=128, bias=True)
      (1): Dropout(p=0.0, inplace=False)
      (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=256, bias=True)
      (5): Dropout(p=0.0, inplace=False)
      (6): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (7): ReLU()
      (8): Linear(in_features=256, out_features=768, bias=True)
      (9): Dropout(p=0.0, inplace=False)
      (10): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (11): ReLU()
    )
  )
  (mha): MultiheadAttention(
    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
  )
  (multi_dense_layer_2): MultiDenseLayer(
    (linear_layer): Sequential(
      (0): Linear(in_features=768, out_features=512, bias=True)
      (1): Dropout(p=0.0, inplace=False)
      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (3): ReLU()
      (4): Linear(in_features=512, out_features=512, bias=True)
      (5): Dropout(p=0.0, inplace=False)
      (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (7): ReLU()
      (8): Linear(in_features=512, out_features=512, bias=True)
      (9): Dropout(p=0.0, inplace=False)
      (10): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (11): ReLU()
    )
  )
  (adjM_layer): MultiDenseLayer(
    (linear_layer): Sequential(
      (0): Linear(in_features=512, out_features=2500, bias=True)
      (1): Dropout(p=0.0, inplace=False)
      (2): LayerNorm((2500,), eps=1e-05, elementwise_affine=True)
      (3): ReLU()
    )
  )
)
INFO:root:G
INFO:root:The number of parameters: 4805836
INFO:root:Discriminator(
  (activation_f): ReLU()
  (multi_dense_layer): MultiDenseLayer(
    (linear_layer): Sequential(
      (0): Linear(in_features=50, out_features=128, bias=True)
      (1): Dropout(p=0.0, inplace=False)
      (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): Dropout(p=0.0, inplace=False)
      (6): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (7): ReLU()
    )
  )
  (multi_dense_layer_2): MultiDenseLayer(
    (linear_layer): Sequential(
      (0): Linear(in_features=6400, out_features=512, bias=True)
      (1): Dropout(p=0.0, inplace=False)
      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (3): ReLU()
      (4): Linear(in_features=512, out_features=768, bias=True)
      (5): Dropout(p=0.0, inplace=False)
      (6): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (7): ReLU()
    )
  )
  (mha): MultiheadAttention(
    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
  )
  (multi_dense_layer_3): MultiDenseLayer(
    (linear_layer): Sequential(
      (0): Linear(in_features=768, out_features=512, bias=True)
      (1): Dropout(p=0.0, inplace=False)
      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (3): ReLU()
      (4): Linear(in_features=512, out_features=256, bias=True)
      (5): Dropout(p=0.0, inplace=False)
      (6): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (7): ReLU()
      (8): Linear(in_features=256, out_features=128, bias=True)
      (9): Dropout(p=0.0, inplace=False)
      (10): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (11): ReLU()
    )
  )
  (output_layer): Linear(in_features=128, out_features=1, bias=True)
)
INFO:root:D
INFO:root:The number of parameters: 6619649
INFO:root:RewardNet(
  (node_cnt): Sequential(
    (0): Linear(in_features=2500, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=1, bias=True)
    (5): Sigmoid()
  )
)
INFO:root:R
INFO:root:The number of parameters: 673281
INFO:root:RobertaModel(
  (embeddings): RobertaEmbeddings(
    (word_embeddings): Embedding(50265, 768, padding_idx=1)
    (position_embeddings): Embedding(514, 768, padding_idx=1)
    (token_type_embeddings): Embedding(1, 768)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (encoder): RobertaEncoder(
    (layer): ModuleList(
      (0-11): 12 x RobertaLayer(
        (attention): RobertaAttention(
          (self): RobertaSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): RobertaSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): RobertaIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (intermediate_act_fn): GELUActivation()
        )
        (output): RobertaOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (pooler): RobertaPooler(
    (dense): Linear(in_features=768, out_features=768, bias=True)
    (activation): Tanh()
  )
)
INFO:root:roberta-base_G
INFO:root:The number of parameters: 124645632
INFO:root:RobertaModel(
  (embeddings): RobertaEmbeddings(
    (word_embeddings): Embedding(50265, 768, padding_idx=1)
    (position_embeddings): Embedding(514, 768, padding_idx=1)
    (token_type_embeddings): Embedding(1, 768)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (encoder): RobertaEncoder(
    (layer): ModuleList(
      (0-11): 12 x RobertaLayer(
        (attention): RobertaAttention(
          (self): RobertaSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): RobertaSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): RobertaIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (intermediate_act_fn): GELUActivation()
        )
        (output): RobertaOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (pooler): RobertaPooler(
    (dense): Linear(in_features=768, out_features=768, bias=True)
    (activation): Tanh()
  )
)
INFO:root:roberta-base_D
INFO:root:The number of parameters: 124645632
INFO:root:Namespace(lm_model='roberta-base', N=50, max_len=128, z_dim=8, mha_dim=768, n_heads=8, gen_dims=[[128, 256, 768], [512, 512, 512]], disc_dims=[[128, 128], [512, 768], [512, 256, 128]], lambda_gp=5, lambda_rew=0.5, lambda_wgan=1, post_method='hard_gumbel', batch_size=128, num_epochs=100, g_lr=0.0002, d_lr=0.0002, b_lr=1e-05, r_lr=0.001, dropout=0.0, n_critic=4, test_epochs=100, num_workers=1, mode='train', bert_unfreeze=0, data_dir='data/graphgen', saving_dir='results/2023-04-22_12-50', model_save_step=20, lr_update_step=1000, restore_G=None, restore_D=None, restore_R=None, restore_B_D=None, restore_B_G=None, name='symm_fcn_final_ds_gumbel_roberta_adjonly_rew', log_dir='results/2023-04-22_12-50/logs', model_dir='results/2023-04-22_12-50/models')
INFO:root:Generator(
  (activation_f): ReLU()
  (multi_dense_layer): MultiDenseLayer(
    (linear_layer): Sequential(
      (0): Linear(in_features=8, out_features=128, bias=True)
      (1): Dropout(p=0.0, inplace=False)
      (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=256, bias=True)
      (5): Dropout(p=0.0, inplace=False)
      (6): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (7): ReLU()
      (8): Linear(in_features=256, out_features=768, bias=True)
      (9): Dropout(p=0.0, inplace=False)
      (10): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (11): ReLU()
    )
  )
  (mha): MultiheadAttention(
    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
  )
  (multi_dense_layer_2): MultiDenseLayer(
    (linear_layer): Sequential(
      (0): Linear(in_features=768, out_features=512, bias=True)
      (1): Dropout(p=0.0, inplace=False)
      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (3): ReLU()
      (4): Linear(in_features=512, out_features=512, bias=True)
      (5): Dropout(p=0.0, inplace=False)
      (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (7): ReLU()
      (8): Linear(in_features=512, out_features=512, bias=True)
      (9): Dropout(p=0.0, inplace=False)
      (10): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (11): ReLU()
    )
  )
  (adjM_layer): MultiDenseLayer(
    (linear_layer): Sequential(
      (0): Linear(in_features=512, out_features=2500, bias=True)
      (1): Dropout(p=0.0, inplace=False)
      (2): LayerNorm((2500,), eps=1e-05, elementwise_affine=True)
      (3): ReLU()
    )
  )
)
INFO:root:G
INFO:root:The number of parameters: 4805836
INFO:root:Discriminator(
  (activation_f): ReLU()
  (multi_dense_layer): MultiDenseLayer(
    (linear_layer): Sequential(
      (0): Linear(in_features=50, out_features=128, bias=True)
      (1): Dropout(p=0.0, inplace=False)
      (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): Dropout(p=0.0, inplace=False)
      (6): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (7): ReLU()
    )
  )
  (multi_dense_layer_2): MultiDenseLayer(
    (linear_layer): Sequential(
      (0): Linear(in_features=6400, out_features=512, bias=True)
      (1): Dropout(p=0.0, inplace=False)
      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (3): ReLU()
      (4): Linear(in_features=512, out_features=768, bias=True)
      (5): Dropout(p=0.0, inplace=False)
      (6): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (7): ReLU()
    )
  )
  (mha): MultiheadAttention(
    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
  )
  (multi_dense_layer_3): MultiDenseLayer(
    (linear_layer): Sequential(
      (0): Linear(in_features=768, out_features=512, bias=True)
      (1): Dropout(p=0.0, inplace=False)
      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (3): ReLU()
      (4): Linear(in_features=512, out_features=256, bias=True)
      (5): Dropout(p=0.0, inplace=False)
      (6): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (7): ReLU()
      (8): Linear(in_features=256, out_features=128, bias=True)
      (9): Dropout(p=0.0, inplace=False)
      (10): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (11): ReLU()
    )
  )
  (output_layer): Linear(in_features=128, out_features=1, bias=True)
)
INFO:root:D
INFO:root:The number of parameters: 6619649
INFO:root:RewardNet(
  (node_cnt): Sequential(
    (0): Linear(in_features=2500, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=1, bias=True)
    (5): Sigmoid()
  )
)
INFO:root:R
INFO:root:The number of parameters: 673281
INFO:root:RobertaModel(
  (embeddings): RobertaEmbeddings(
    (word_embeddings): Embedding(50265, 768, padding_idx=1)
    (position_embeddings): Embedding(514, 768, padding_idx=1)
    (token_type_embeddings): Embedding(1, 768)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (encoder): RobertaEncoder(
    (layer): ModuleList(
      (0-11): 12 x RobertaLayer(
        (attention): RobertaAttention(
          (self): RobertaSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): RobertaSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): RobertaIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (intermediate_act_fn): GELUActivation()
        )
        (output): RobertaOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (pooler): RobertaPooler(
    (dense): Linear(in_features=768, out_features=768, bias=True)
    (activation): Tanh()
  )
)
INFO:root:roberta-base_G
INFO:root:The number of parameters: 124645632
INFO:root:RobertaModel(
  (embeddings): RobertaEmbeddings(
    (word_embeddings): Embedding(50265, 768, padding_idx=1)
    (position_embeddings): Embedding(514, 768, padding_idx=1)
    (token_type_embeddings): Embedding(1, 768)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (encoder): RobertaEncoder(
    (layer): ModuleList(
      (0-11): 12 x RobertaLayer(
        (attention): RobertaAttention(
          (self): RobertaSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): RobertaSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): RobertaIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (intermediate_act_fn): GELUActivation()
        )
        (output): RobertaOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (pooler): RobertaPooler(
    (dense): Linear(in_features=768, out_features=768, bias=True)
    (activation): Tanh()
  )
)
INFO:root:roberta-base_D
INFO:root:The number of parameters: 124645632
INFO:root:5 sample adjacenecy matrices
--------------------------------------------------
Text: Undirected graph with no cycle, 5 nodes, max degree 3, max diameter 3, 4 edges.
Results: [50, 768, 22, 37, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with 10 edges, one or more cycle, 10 nodes, max degree 4, max diameter 5.
Results: [50, 766, 21, 39, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with max diameter 4, max degree 15, 30 nodes, min degree 1, one or more cycle, 51 edges, 1 connected component.
Results: [50, 757, 24, 38, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with 23 nodes, 1 connected component, one or more cycle, 54 edges, max diameter 4, max degree 8, min degree 2.
Results: [50, 769, 23, 38, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with max degree 13, 116 edges, 45 nodes, min degree 1.
Results: [50, 771, 23, 40, 2, 1, True]
--------------------------------------------------

INFO:root:Saved model checkpoints into results/2023-04-22_12-50/models...
INFO:root:Elapsed [0:08:11], Iteration [0/100]:
l_D/R: -0.32, l_D/F: -0.32, l_D: 4.85, l_G: 0.32, l_R: 0.45, l_R/N: 0.08, l_R/M: 0.36
property_match: 0.23, closeness: 0.25, n_match: 0.02, m_match: 0.00, min_deg_match: 0.00, max_deg_match: 0.00, diam_match: 0.05, cc_match: 0.60, cycle_match: 0.61
INFO:root:5 sample adjacenecy matrices
--------------------------------------------------
Text: Undirected graph with 5 nodes, 4 edges, max diameter 3, min degree 1, 1 connected component.
Results: [50, 787, 24, 38, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with 10 edges, 1 connected component, one or more cycle, max diameter 5, min degree 1, max degree 4, 10 nodes.
Results: [50, 773, 25, 37, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with 51 edges, one or more cycle, 1 connected component, 30 nodes.
Results: [50, 776, 22, 39, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with 23 nodes, max degree 8, 54 edges, 1 connected component.
Results: [50, 792, 24, 38, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with max degree 13, 1 connected component, 45 nodes, min degree 1, 116 edges, max diameter 11.
Results: [50, 792, 24, 39, 2, 1, True]
--------------------------------------------------

INFO:root:Saved model checkpoints into results/2023-04-22_12-50/models...
INFO:root:Elapsed [0:07:58], Iteration [0/100]:
l_D/R: 0.71, l_D/F: 0.71, l_D: 4.85, l_G: -0.71, l_R: 0.45, l_R/N: 0.08, l_R/M: 0.36
property_match: 0.23, closeness: 0.25, n_match: 0.02, m_match: 0.00, min_deg_match: 0.00, max_deg_match: 0.00, diam_match: 0.05, cc_match: 0.61, cycle_match: 0.62
INFO:root:5 sample adjacenecy matrices
--------------------------------------------------
Text: Undirected graph with 1 connected component, 4 edges, max degree 3, 5 nodes.
Results: [50, 664, 18, 36, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with min degree 1, one or more cycle, 10 edges, 10 nodes, max degree 4, 1 connected component.
Results: [50, 670, 17, 38, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with 30 nodes, 1 connected component, 51 edges, max degree 15.
Results: [50, 691, 18, 37, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with 54 edges, min degree 2, 23 nodes, one or more cycle.
Results: [50, 697, 16, 39, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with min degree 1, 1 connected component, 116 edges, 45 nodes.
Results: [50, 687, 19, 39, 2, 1, True]
--------------------------------------------------

INFO:root:Elapsed [0:13:32], Iteration [1/100]:
l_D/R: 13.25, l_D/F: -9.59, l_D: -22.29, l_G: 9.59, l_R: 0.36, l_R/N: 0.08, l_R/M: 0.27
INFO:root:5 sample adjacenecy matrices
--------------------------------------------------
Text: Undirected graph with 5 nodes, 4 edges, max diameter 3, no cycle.
Results: [50, 681, 20, 45, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with 10 edges, 10 nodes, 1 connected component, one or more cycle, max diameter 5, max degree 4.
Results: [50, 676, 19, 45, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with max degree 15, min degree 1, max diameter 4, 51 edges, 30 nodes, 1 connected component.
Results: [50, 698, 20, 42, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with 54 edges, max diameter 4, 23 nodes, max degree 8, 1 connected component.
Results: [50, 670, 17, 41, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with max degree 13, 45 nodes, 1 connected component, 116 edges.
Results: [50, 684, 21, 44, 2, 1, True]
--------------------------------------------------

INFO:root:Elapsed [0:13:11], Iteration [1/100]:
l_D/R: 13.95, l_D/F: -14.25, l_D: -24.83, l_G: 14.25, l_R: 0.36, l_R/N: 0.08, l_R/M: 0.27
INFO:root:5 sample adjacenecy matrices
--------------------------------------------------
Text: Undirected graph with 4 edges, no cycle, min degree 1, 1 connected component, max degree 3, max diameter 3, 5 nodes.
Results: [50, 645, 19, 34, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with max degree 4, 10 edges, 10 nodes, 1 connected component.
Results: [50, 637, 16, 34, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with max diameter 4, 30 nodes, 51 edges, one or more cycle, min degree 1, max degree 15.
Results: [50, 621, 16, 33, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with min degree 2, 54 edges, max degree 8, 23 nodes.
Results: [50, 630, 19, 32, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with 116 edges, min degree 1, max degree 13, 45 nodes, 1 connected component.
Results: [50, 646, 17, 32, 2, 1, True]
--------------------------------------------------

INFO:root:Elapsed [0:18:57], Iteration [2/100]:
l_D/R: 27.58, l_D/F: -27.80, l_D: -47.34, l_G: 27.82, l_R: 0.32, l_R/N: 0.08, l_R/M: 0.24
INFO:root:5 sample adjacenecy matrices
--------------------------------------------------
Text: Undirected graph with 4 edges, 1 connected component, max diameter 3, min degree 1, 5 nodes, max degree 3, no cycle.
Results: [50, 616, 17, 32, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with max degree 4, 1 connected component, 10 edges, min degree 1, one or more cycle, max diameter 5, 10 nodes.
Results: [50, 627, 15, 36, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with 30 nodes, one or more cycle, 51 edges, max degree 15, max diameter 4, min degree 1, 1 connected component.
Results: [50, 625, 17, 35, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with min degree 2, 54 edges, max degree 8, one or more cycle, 23 nodes, 1 connected component.
Results: [50, 641, 19, 33, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with max diameter 11, 116 edges, min degree 1, one or more cycle, 45 nodes.
Results: [50, 645, 17, 33, 2, 1, True]
--------------------------------------------------

INFO:root:Elapsed [0:18:26], Iteration [2/100]:
l_D/R: 27.95, l_D/F: -29.81, l_D: -45.82, l_G: 29.80, l_R: 0.32, l_R/N: 0.08, l_R/M: 0.24
INFO:root:5 sample adjacenecy matrices
--------------------------------------------------
Text: Undirected graph with 4 edges, no cycle, 5 nodes, max diameter 3, 1 connected component.
Results: [50, 653, 18, 33, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with 1 connected component, 10 edges, 10 nodes, max diameter 5, one or more cycle, max degree 4.
Results: [50, 611, 16, 32, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with max degree 15, 30 nodes, 51 edges, 1 connected component.
Results: [50, 641, 18, 34, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with 23 nodes, min degree 2, max diameter 4, 1 connected component, 54 edges.
Results: [50, 645, 18, 34, 2, 1, True]
--------------------------------------------------
--------------------------------------------------
Text: Undirected graph with 1 connected component, 116 edges, min degree 1, max diameter 11, one or more cycle, 45 nodes, max degree 13.
Results: [50, 646, 18, 33, 2, 1, True]
--------------------------------------------------

INFO:root:Elapsed [0:24:22], Iteration [3/100]:
l_D/R: 31.93, l_D/F: -14.13, l_D: -39.31, l_G: 14.12, l_R: 0.32, l_R/N: 0.08, l_R/M: 0.24
